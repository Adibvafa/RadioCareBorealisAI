{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: CNN.ipynb\n",
    "------------------\n",
    "A beginner notebook on training and validating a CNN model on the MIMIC-CXR dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Conv2d, Linear, ReLU, MaxPool2d, Dropout, BatchNorm2d\n",
    "\n",
    "from lib.utils import seed_everything\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device set to: {torch.cuda.get_device_name(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    seed = 23\n",
    "    train_batch_size = 32\n",
    "    valid_batch_size = 128\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 10\n",
    "    num_classes = 2\n",
    "\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    \"\"\" \n",
    "    Basic CNN model for chest xray classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, in_channels=1, output_size=2):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # First convolutional layer\n",
    "        self.conv1 = Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = BatchNorm2d(32)\n",
    "\n",
    "        # Second convolutional layer\n",
    "        self.conv2 = Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = BatchNorm2d(64)\n",
    "\n",
    "        # Third convolutional layer\n",
    "        self.conv3 = Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = BatchNorm2d(128)\n",
    "\n",
    "        # Fourth convolutional layer\n",
    "        self.conv4 = Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = BatchNorm2d(256)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = Linear(256*input_shape*input_shape, 512)\n",
    "        self.fc2 = Linear(512, output_size)\n",
    "\n",
    "        # Activation, pooling and dropout layers\n",
    "        self.relu = ReLU()\n",
    "        self.maxpool = MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through first convolutional block\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Pass through second convolutional lblock\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Pass through third convolutional lablock\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Pass through fourth convolutional lblock\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Pass through first fully connected block\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Pass through second fully connectedblock\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get dataset\n",
    "train_dataset = None\n",
    "val_dataset = None\n",
    "input_shape = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and validation dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.train_batch_size, shuffle=True, ranom_seed=config.seed)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config.valid_batch_size, shuffle=False)\n",
    "\n",
    "# Create an instance of the CNN model\n",
    "model = CNN(input_shape=input_shape, output_size=config.num_classes).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config.num_epochs):\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_dataloader,\n",
    "                               unit=\"train batch\", len=len(train_dataloader),\n",
    "                               desc=f\"Training epoch {epoch+1}/{config.num_epochs}...\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        total_train_samples += labels.size(0)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_accuracy = train_correct / total_train_samples\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    total_val_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_dataloader, \n",
    "                                   unit=\"val batch\",len=len(train_dataloader),\n",
    "                                   desc=f\"Validating epoch {epoch+1}/{config.num_epochs}...\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            total_val_samples += labels.size(0)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_accuracy = val_correct / total_val_samples\n",
    "    val_loss /= len(val_dataloader)\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"\\nEpoch {epoch+1}/{config.num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "light",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
