{
    "cells": [
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "import sys\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "\n",
       "from pathlib import Path\n",
       "from PIL import Image\n",
       "\n",
       "from tqdm import tqdm\n",
       "\n",
       "import tensorflow as tf\n",
       "\n",
       "from transformers import ViTFeatureExtractor, TFAutoModelForImageClassification\n",
       "from transformers import ViTForImageClassification, ViTConfig, ViTImageProcessor\n",
       "\n",
       "from sklearn.model_selection import train_test_split\n",
       "\n",
       "\n",
       "import torch\n",
       "import torch.optim as optim\n",
       "import torch.nn as nn\n",
       "from torchvision.datasets import ImageFolder\n",
       "from torch.utils.data import DataLoader\n",
       "\n",
       "DATA_DIR  = 'mimic-data/'\n",
       "ROOT = os.path.dirname(os.getcwd())\n",
       "os.chdir(f'E:/RadioCareBorealisAI')\n",
       "\n",
       "from data_modules.mimic_cxr import MimicIVCXR\n",
       "\n",
       "def seed_everything(seed: int) -> None:\n",
       "    \"\"\" Seed everything for reproducibility.\"\"\"\n",
       "    np.random.seed(seed)\n",
       "    torch.manual_seed(seed)\n",
       "    torch.cuda.manual_seed(seed)\n",
       "    torch.cuda.manual_seed_all(seed)\n",
       "    torch.backends.cudnn.deterministic = True\n",
       "    torch.backends.cudnn.benchmark = False\n",
       "    torch.backends.cudnn.enabled = False"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "class args:\n",
       "    seed = 23\n",
       "    train_batch_size = 48\n",
       "    valid_batch_size = 16\n",
       "    test_batch_size = 16\n",
       "    num_labels = 2\n",
       "    num_epochs = 5\n",
       "\n",
       "# Set your device\n",
       "seed_everything(args.seed)\n",
       "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "graph_report_dir = f\"{DATA_DIR}/graph_report.csv\"\n",
       "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
       "\n",
       "dataset = MimicIVCXR(data_root=DATA_DIR,\n",
       "                     graph_report_dir=graph_report_dir,\n",
       "                     tokenizer=\"AutoTokenizer.from_pretrained('bert-base-uncased')\",\n",
       "                     max_length=3000,\n",
       "                     transform=processor)\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "class LimitedDataset:\n",
       "    def __init__(self, full_dataset, limit=20000):\n",
       "        self.full_dataset = full_dataset\n",
       "        self.limit = min(limit, len(full_dataset))\n",
       "\n",
       "    def __getitem__(self, index):\n",
       "        if index < self.limit:\n",
       "            return self.full_dataset[index]\n",
       "        else:\n",
       "            raise IndexError(\"Index out of range\")\n",
       "\n",
       "    def __len__(self):\n",
       "        return self.limit\n",
       "\n",
       "# Example usage:\n",
       "dataset = LimitedDataset(dataset)\n",
       "\n",
       "# Now you can use limited_dataset with indexing up to 20,000\n",
       "print(len(dataset))  # Should print 20000\n",
       "print(dataset[19999])  # Accessing the last item within the limit"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# train_data, val_test_data = train_test_split(dataset, test_size=0.2)\n",
       "# val_data, test_data = train_test_split(val_test_data, test_size=0.5)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Load your data and create dataloaders\n",
       "train_dataloader = DataLoader(dataset, batch_size=args.train_batch_size, shuffle=False)\n",
       "# val_dataloader = DataLoader(val_data, batch_size=args.valid_batch_size, shuffle=False)\n",
       "# test_dataloader = DataLoader(test_data, batch_size=args.test_batch_size, shuffle=False)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "config = ViTConfig.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=args.num_labels)\n",
       "model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\",\n",
       "                                                  config=config)\n",
       "model.to(device)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "criterion = nn.CrossEntropyLoss()\n",
       "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
       "\n",
       "train_losses = []\n",
       "val_accuracies = []\n",
       "\n",
       "for epoch in range(args.num_epochs):\n",
       "\n",
       "    model.train()\n",
       "    running_loss = 0.0\n",
       "    for images, _, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{args.num_epochs}\", unit=\"batch\", total=len(train_dataloader)):\n",
       "        images, labels = images.to(device), labels.to(device)\n",
       "        optimizer.zero_grad()\n",
       "        \n",
       "        outputs = model(images).logits\n",
       "        loss = criterion(outputs, labels)\n",
       "        loss.backward()\n",
       "        optimizer.step()\n",
       "        \n",
       "        running_loss += loss.item() * images.size(0)\n",
       "\n",
       "    avg_train_loss = running_loss / len(train_dataloader)\n",
       "    train_losses.append(avg_train_loss)\n",
       "\n",
       "    # Validation phase\n",
       "    model.eval()\n",
       "    correct = 0\n",
       "    total = 0\n",
       "    # with torch.no_grad():\n",
       "    #     for images, _, labels in val_dataloader:\n",
       "    #         images, labels = images.to(device), labels.to(device)\n",
       "    #         outputs = model(images).logits\n",
       "    #         _, predicted = outputs.max(1)\n",
       "    #         total += labels.size(0)\n",
       "    #         correct += (predicted == labels).sum().item()\n",
       "    \n",
       "    val_accuracy = 100 * correct / total\n",
       "    val_accuracies.append(val_accuracy)\n",
       "    \n",
       "    print(f\"Epoch {epoch+1}/{args.num_epochs}, Loss: {avg_train_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "running_loss / len(train_dataloader)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "correct = 0\n",
       "total = 0\n",
       "\n",
       "with torch.no_grad():\n",
       "    model.eval()\n",
       "\n",
       "    for images, text, labels in test_dataloader:\n",
       "        images, labels = images.to(device), labels.to(device)\n",
       "        outputs = model(images).logits\n",
       "        _, predicted = outputs.max(1)\n",
       "        total += labels.size(0)\n",
       "        correct += (predicted == labels).sum().item()\n",
       "\n",
       "test_accuracy = 100 * correct / total\n",
       "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }
   